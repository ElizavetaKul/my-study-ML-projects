# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ibWmmRldEzea1xEluMeJxO1ck5hO3zGT

ЗАДАНИЕ
- Выберите набор данных для задачи обучения с учителем.
- Разбейте его на три части.
- Выберите три разных простых алгоритма обучения с учителем.
- Обучите на первой части набора данных все три алгоритма.
- Для каждого объекта из второго набора данных определите, какой алгоритм лучше всего строит предсказание на них.
- Обучите на полученной информации мета-алгоритм, который будет определять, какой алгоритм лучше выбирать.
- Протестируйте полученный ансамбль на третьей части набора данных.
- Сравните результат с существующим ансамблем из библиотеки. Не забывайте, что его нужно обучать на объединённой первой и второй части набора данных.
"""

import pandas as pd
import math
import numpy as np

# Импортируем датасет
data = pd.read_csv('/content/geyser.csv')

y = data["class"].map(lambda c: ord(c) - ord('O'))
X = data.drop(columns=['class']).to_numpy()

"""Разделим набор данных на 3 части"""

X_1, X_2, X_3 = np.split(X, indices_or_sections = 3)

X_1.shape, X_2.shape, X_3.shape

y_1, y_2, y_3 = np.split(y, indices_or_sections = 3)

y_1.shape, y_2.shape, y_3.shape

"""Обучим алгоритм SVC"""

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

param_svc = {'C': [0.1, 0.5, 1, 5, 10],
              'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}
grid_svc = GridSearchCV(SVC(), param_svc)
grid_svc.fit(X_1, y_1)
print('Best params for SVC are:', grid_svc.best_params_)

svc = SVC(C = 0.1, gamma = 0.00001, kernel='linear', probability=True)
svc.fit(X_1, y_1)
prob_svc = svc.predict_proba(X_2)

prob_svc

"""Обучим DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier

param_dt = {'criterion': ['gini', 'entropy', 'log_loss'],
             'max_depth': [2, 3, 6, 9, 12, 15, 18, 20, None],
             'max_leaf_nodes': [2, 5, 8, 11, None]}
grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=1), param_dt)
grid_dt.fit(X_1, y_1)
print('Best params for DecisionTreeClassifier are:', grid_dt.best_params_)

dt_clf = DecisionTreeClassifier(criterion = 'gini', max_depth=2, max_leaf_nodes=2)
dt_clf.fit(X_1, y_1)
prob_dt = dt_clf.predict_proba(X_2)

"""Обучим KNeighbours Classifier"""

from sklearn.neighbors import KNeighborsClassifier

param_knn = {'n_neighbors': [5, 8, 11, 14, 17, 20],
             'weights': ['uniform', 'distance']}
grid_knn = GridSearchCV(KNeighborsClassifier(), param_knn)
grid_knn.fit(X_1, y_1)
print('Best params for KNeighborsClassifier are:', grid_knn.best_params_)

knn_clf = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform')
knn_clf.fit(X_1, y_1)
prob_knn = knn_clf.predict_proba(X_2)

"""Теперь у нас есть вероятностные предсказания трех алгоритмов"""

print(prob_svc.shape)
print(prob_dt.shape)
print(prob_knn.shape)

"""Чтобы определить, какой алгоритм точнее всего делает предсказания для реальных классов, извлечем значения вероятностей, полученные по результатам работы 3х алгоритмов"""

# SVC
i = 0
true_class_prob_svc = []
for real_y in y_2:
    if real_y == -1:
        true_class_prob_svc.append(prob_svc[i, 0])
    else:
        true_class_prob_svc.append(prob_svc[i, 1])
    i += 1

true_y_prob_svc = np.array(true_class_prob_svc)
true_y_prob_svc

# DT
n = 0
true_class_prob_dt = []
for real_y in y_2:
    if real_y == -1:
        true_class_prob_dt.append(prob_dt[n, 0])
    else:
        true_class_prob_dt.append(prob_dt[n, 1])
    n += 1

true_y_prob_dt = np.array(true_class_prob_dt)
true_y_prob_dt

# kNN
k = 0
true_class_prob_knn = []
for real_y in y_2:
    if real_y == -1:
        true_class_prob_knn.append(prob_knn[k, 0])
    else:
        true_class_prob_knn.append(prob_knn[k, 1])
    k += 1

true_y_prob_knn = np.array(true_class_prob_knn)
true_y_prob_knn

# Объединим полученные вероятности
meta_df = pd.DataFrame(data=0, index=range(len(X_2)), columns=['svc', 'dt', 'knn'])

meta_df['svc'] = true_y_prob_svc
meta_df['dt'] = true_y_prob_dt
meta_df['knn'] = true_y_prob_knn
all_alg_probs = meta_df.to_numpy()

meta_df

# Для каждого объекта выборки X_2 найдем алгоритм, который был наиболее уверен в ответе на этом объекте
best_alg = np.argmax(all_alg_probs, axis=1)
best_alg

"""Обучим мета-алгоритм"""

meta = SVC()
meta.fit(X_2, best_alg)

# Теперь у нас есть мета-алгоритм, который для нового объекта может выбрать наилучший из 3-х алгоритмов.
# Протестируем на третьей части набора данных.

meta_choice = []

for x in X_3:
    x = x.reshape(1, -1)
    alg_predict = meta.predict(x)
    if alg_predict == 0:
        y_pred = svc.predict(x)
    elif alg_predict == 1:
        y_pred = dt_clf.predict(x)
    elif alg_predict == 2:
        y_pred = knn_clf.predict(x)
    meta_choice.append(y_pred)

y_meta = np.array(meta_choice)

"""Протестируем алгоритм GradientBoostingClassifier"""

# Объединим X_1 и X_2 в один массив X_train
X_train = np.concatenate([X_1, X_2])
y_train = np.concatenate([y_1, y_2])

from sklearn.ensemble import GradientBoostingClassifier
param_boost = {'loss': ['log_loss', 'exponential'],
              'n_estimators': [100, 200, 300, 500, 700]}
grid_boost = GridSearchCV(GradientBoostingClassifier(), param_boost)
grid_boost.fit(X_train, y_train)
print(grid_boost.best_params_)

grad_boost = GradientBoostingClassifier(loss='log_loss', n_estimators=100)
grad_boost.fit(X_train, y_train)

y_boost = grad_boost.predict(X_3)

"""Сравним результаты работы нашего мета-алгоритма и GradientBoostingClassifier



"""

from sklearn.metrics import accuracy_score
meta_acc_score = accuracy_score(y_3, y_meta)
boost_acc_score = accuracy_score(y_3, y_boost)
print(f'Accuracy score for meta algorithm is {meta_acc_score}')
print(f'Accuracy score for GradientBoostingClassifier is {boost_acc_score}')

"""Показатели accuracy для мета-алгоритма оказались чуть выше, чем у градиентного бустинга.

Посмотрим на количество TN, TP, FN, FP объектов:
"""

from sklearn.metrics import confusion_matrix

tn_meta, fp_meta, fn_meta, tp_meta = confusion_matrix(y_3, y_meta).ravel()
tn_meta, fp_meta, fn_meta, tp_meta

tn_boost, fp_boost, fn_boost, tp_boost = confusion_matrix(y_3, y_boost).ravel()
tn_boost, fp_boost, fn_boost, tp_boost