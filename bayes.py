# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YDIO2pi94QedoCdONE_1nuTpkFhz_Igr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import cross_val_score, train_test_split

import sklearn.metrics as metrics

from sklearn.metrics import confusion_matrix

# Загрузим набор данных с СМС-сообщениями.

df = pd.read_csv("/content/SMS.tsv", sep='\t', header=None, names=["class", "text"])
df

# Рассмотрим один из алгоритмов векторизации текста
vec = CountVectorizer()

X = vec.fit_transform(df["text"])
y = df["class"]

"""Сразу поменяем метки классов со словесных на [-1, +1], чтобы избежать ошибок:
класс spam пометим как положительный (+1), класс ham как отрицательный (-1).
"""

y = y.map(lambda x: -1 if x == "ham" else 1)

# Построим график зависимости точности от гиперпараметра alpha
# Заметим, что всё самое интересное происходит в районе нуля.
# Поэтому границы интервала поиска нужно сузить.
# После построения графика можно попробовать сузить их ещё раз.

alpha_list = np.linspace(1e-9, 100)
acuracy_list = []

for alpha in alpha_list:
    acuracy_list.append(cross_val_score(MultinomialNB(alpha=alpha), X, y, cv=3).mean())

plt.xlabel('alpha')
plt.ylabel('acuracy')
plt.plot(alpha_list, acuracy_list)
plt.show()

"""Сузим границы поиска"""

alpha_list = np.linspace(1e-9, 10)
acuracy_list = []

for alpha in alpha_list:
    acuracy_list.append(cross_val_score(MultinomialNB(alpha=alpha), X, y, cv=3).mean())

plt.xlabel('alpha')
plt.ylabel('acuracy')
plt.plot(alpha_list, acuracy_list)
plt.show()

print('Max accuracy score is ', max(acuracy_list))
score_index = acuracy_list.index(max(acuracy_list))
print('Alpha for max accuracy is ', alpha_list[score_index])

alpha_list = np.linspace(1e-9, 5)
acuracy_list = []

for alpha in alpha_list:
    acuracy_list.append(cross_val_score(MultinomialNB(alpha=alpha), X, y, cv=3).mean())

plt.xlabel('alpha')
plt.ylabel('acuracy')
plt.plot(alpha_list, acuracy_list)
plt.show()

print('Max accuracy score is ', max(acuracy_list))
score_index = acuracy_list.index(max(acuracy_list))
print('Alpha for max accuracy is ', alpha_list[score_index])


# Заменим CountVectorizer на TfidfVectorizer и
# повторим эксперимент с поиском гиперпараметра alpha.
vec_tfidf = TfidfVectorizer()

X_2 = vec_tfidf.fit_transform(df["text"])

alpha_list = np.linspace(1e-9, 2)
acuracy_list = []

for alpha in alpha_list:
    acuracy_list.append(cross_val_score(MultinomialNB(alpha=alpha), X_2, y, cv=3).mean())

plt.xlabel('alpha')
plt.ylabel('acuracy')
plt.plot(alpha_list, acuracy_list)
plt.show()

print('Max accuracy score is ', max(acuracy_list))
score_index = acuracy_list.index(max(acuracy_list))
print('Alpha for max accuracy is ', alpha_list[score_index])

log_alpha_list = np.linspace(-4, 3)
alpha_list = np.exp(log_alpha_list)
acuracy_list = []

for alpha in alpha_list:
    acuracy_list.append(cross_val_score(MultinomialNB(alpha=alpha), X_2, y, cv=3).mean())

plt.xlabel('log_alpha')
plt.ylabel('acuracy')
plt.plot(log_alpha_list, acuracy_list)
plt.show()

print('Max accuracy score is ', max(acuracy_list))
score_index = acuracy_list.index(max(acuracy_list))
print('Alpha for max accuracy is ', alpha_list[score_index])

# Зафиксируем оптимальную найденную alpha
alpha_best = 0.1
print(cross_val_score(MultinomialNB(alpha=alpha_best), X_2, y, cv=3).mean())


# Построим ROC-кривую и вычислим AUC метрику.

# Для этого разобьём набор данных на train и test часть.
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

# Обучим классификатор.
clf = MultinomialNB(alpha=alpha_best)
clf.fit(X_train, y_train)

probs = clf.predict_proba(X_test)

# Объект probs многомерный, так как каждое предсказание - это вектор вероятностей.
# Для построения ROC-кривой из двух вероятностей (столбцов) оставим только вероятность принадлежности одному классу.
preds = probs[:,1]

# Получим значения fpr и tpr, а также соответствующие границы threshold.

fpr, tpr, threshold = metrics.roc_curve(y_test, preds)
roc_auc = metrics.auc(fpr, tpr)

# Построим ROC-кривую. 

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.4f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Проверим метки классов
clf.classes_

"""Число хороших сообщений, попадающих в спам - это количество false positive объектов. Измерим его с помощью метрики confusion matrix.   """

# Постараемся снизить число хороших сообщений попадающих в спам.

log_prob_spam_list = np.linspace(-40, -1)
prob_spam_list = np.exp(log_prob_spam_list)
acuracy_list = []

num_fp_list = []

for prob_spam in prob_spam_list:
    class_prior = [1 - prob_spam, prob_spam] # Убедитесь, что классы расставлены верно

    clf = MultinomialNB(alpha=alpha_best, fit_prior=False, class_prior=class_prior)
    clf.fit(X_train, y_train)

    # Помимо точности измерим число хороших сообщений попадающих в спам и постройте график.
    acuracy_list.append(clf.score(X_test, y_test))

    y_pred = clf.predict(X_test)
    pos, neg = confusion_matrix(y_test, y_pred)
    num_fp = pos[1]
    num_fp_list.append(num_fp)

# График 1
plt.xlabel('log_prob_spam')
plt.ylabel('acuracy')
plt.plot(log_prob_spam_list, acuracy_list)
plt.show()

# График 2
plt.xlabel('num_false_positive')
plt.ylabel('acuracy')
plt.plot(num_fp_list, acuracy_list)
plt.show()

print('Max accuracy score is ', max(acuracy_list))
score_index = acuracy_list.index(max(acuracy_list))
print('Prior prob for max accuracy is ', prob_spam_list[score_index])

plt.xlabel('num_false_positive')
plt.ylabel('acuracy')
plt.plot(num_fp_list, acuracy_list)


plt.xlim(right=5)
plt.xlim(left=-1)

plt.show()

print('False positive error: ', num_fp_list)

df = pd.DataFrame(zip(acuracy_list, num_fp_list))
df